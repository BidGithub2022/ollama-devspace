# ollama in devspaces

Start an workspace using this devfile:
![Screen Shot 2024-12-25 at 2 09 25 PM](https://github.com/user-attachments/assets/695bdbc2-caff-4516-bb6a-b253aba5042c)

kubectl exec -it workspacede5ada8325014cd5-8c69c9c5d-k4km5 -c ollama -- /bin/bash
ollama run llama3.2
![Screen Shot 2024-12-25 at 2 10 54 PM](https://github.com/user-attachments/assets/1c5d7cbc-6774-4ff3-9c1f-dd8dcbb72b21)
